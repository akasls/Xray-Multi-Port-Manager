#!/usr/bin/env python3
"""
ç®€åŒ–çš„æ€§èƒ½ä¼˜åŒ–æµ‹è¯•
"""
import asyncio
import time
import threading
from unittest.mock import Mock, patch

from xray_gui.core.concurrent_latency_tester import (
    ConcurrentLatencyTester, 
    ConcurrentTestConfig, 
    TestStrategy,
    BatchTestResult
)
from xray_gui.core.system_adaptability_manager import (
    SystemAdaptabilityManager,
    SystemState,
    SystemEvent,
    AdaptationRule
)
from xray_gui.core.node import Node

def test_concurrent_processing_efficiency():
    """æµ‹è¯•å¹¶å‘å¤„ç†æ•ˆç‡æ€§"""
    print("Testing concurrent processing efficiency...")
    
    concurrent_tester = ConcurrentLatencyTester()
    
    # åˆ›å»ºæµ‹è¯•èŠ‚ç‚¹
    node_count = 10
    nodes = []
    for i in range(node_count):
        node = Node(
            uuid=f"test-uuid-{i}",
            remark=f"test_node_{i}",
            protocol="vless",
            address="127.0.0.1",
            port=443 + i
        )
        nodes.append(node)
    
    # é…ç½®å¹¶å‘æµ‹è¯•
    config = ConcurrentTestConfig(
        max_concurrent=5,
        timeout=1.0,  # çŸ­è¶…æ—¶ä»¥åŠ å¿«æµ‹è¯•
        strategy=TestStrategy.THREADING
    )
    
    print(f"  Testing {node_count} nodes with max_concurrent={config.max_concurrent}")
    
    # è®°å½•å¼€å§‹æ—¶é—´
    start_time = time.time()
    
    # æ‰§è¡Œå¹¶å‘æµ‹è¯•
    result = concurrent_tester.test_nodes_threaded(
        nodes=nodes,
        config=config
    )
    
    # è®°å½•ç»“æŸæ—¶é—´
    end_time = time.time()
    test_duration = end_time - start_time
    
    # éªŒè¯å¹¶å‘å¤„ç†æ•ˆç‡
    assert isinstance(result, BatchTestResult), "åº”è¯¥è¿”å›BatchTestResultå¯¹è±¡"
    assert result.total_nodes == node_count, f"æ€»èŠ‚ç‚¹æ•°åº”è¯¥æ˜¯{node_count}ï¼Œå®é™…æ˜¯{result.total_nodes}"
    assert len(result.results) == node_count, f"ç»“æœæ•°é‡åº”è¯¥æ˜¯{node_count}ï¼Œå®é™…æ˜¯{len(result.results)}"
    
    # éªŒè¯å¹¶å‘æ•ˆç‡ï¼šå¹¶å‘æµ‹è¯•åº”è¯¥æ¯”ä¸²è¡Œæµ‹è¯•å¿«
    expected_serial_time = node_count * config.timeout
    efficiency_ratio = expected_serial_time / test_duration
    
    print(f"  å¹¶å‘æµ‹è¯•ç”¨æ—¶: {test_duration:.2f}s")
    print(f"  é¢„æœŸä¸²è¡Œç”¨æ—¶: {expected_serial_time:.2f}s")
    print(f"  æ•ˆç‡æ¯”: {efficiency_ratio:.2f}x")
    
    # å¹¶å‘æ•ˆç‡åº”è¯¥è‡³å°‘æ˜¯ä¸²è¡Œçš„1.5å€ï¼ˆè€ƒè™‘åˆ°æµ‹è¯•ç¯å¢ƒçš„é™åˆ¶ï¼‰
    assert efficiency_ratio > 1.5, f"å¹¶å‘æ•ˆç‡ä¸è¶³ï¼šæ•ˆç‡æ¯”{efficiency_ratio:.2f}åº”è¯¥å¤§äº1.5"
    
    # éªŒè¯ç»“æœå®Œæ•´æ€§
    for i, test_result in enumerate(result.results):
        assert test_result.node_uuid == f"test-uuid-{i}", f"èŠ‚ç‚¹UUIDåº”è¯¥åŒ¹é…"
        assert test_result.timestamp is not None, "åº”è¯¥æœ‰æ—¶é—´æˆ³"
        assert test_result.latency is not None, "åº”è¯¥æœ‰å»¶è¿Ÿç»“æœï¼ˆå¯èƒ½æ˜¯-1è¡¨ç¤ºå¤±è´¥ï¼‰"
    
    # éªŒè¯ç»Ÿè®¡ä¿¡æ¯
    result.update_statistics()
    assert result.total_nodes == node_count, "ç»Ÿè®¡ä¿¡æ¯ä¸­çš„æ€»èŠ‚ç‚¹æ•°åº”è¯¥æ­£ç¡®"
    assert result.completed_nodes >= 0, "å®ŒæˆèŠ‚ç‚¹æ•°åº”è¯¥éè´Ÿ"
    assert result.test_duration >= 0, "æµ‹è¯•æŒç»­æ—¶é—´åº”è¯¥éè´Ÿ"
    
    print("âœ… å¹¶å‘å¤„ç†æ•ˆç‡æ€§æµ‹è¯•é€šè¿‡")

def test_async_vs_threading_strategies():
    """æµ‹è¯•å¼‚æ­¥å’Œçº¿ç¨‹ç­–ç•¥çš„æ•ˆç‡å¯¹æ¯”"""
    print("\nTesting async vs threading strategies...")
    
    concurrent_tester = ConcurrentLatencyTester()
    
    # åˆ›å»ºæµ‹è¯•èŠ‚ç‚¹
    nodes = []
    for i in range(8):
        node = Node(
            uuid=f"strategy-test-{i}",
            remark=f"strategy_node_{i}",
            protocol="vless",
            address="127.0.0.1",
            port=8000 + i
        )
        nodes.append(node)
    
    config = ConcurrentTestConfig(
        max_concurrent=4,
        timeout=0.5,
    )
    
    # æµ‹è¯•çº¿ç¨‹ç­–ç•¥
    print("  Testing threading strategy...")
    config.strategy = TestStrategy.THREADING
    start_time = time.time()
    threading_result = concurrent_tester.test_nodes_threaded(nodes=nodes, config=config)
    threading_duration = time.time() - start_time
    
    # æµ‹è¯•å¼‚æ­¥ç­–ç•¥
    print("  Testing async strategy...")
    config.strategy = TestStrategy.ASYNCIO
    start_time = time.time()
    async_result = asyncio.run(concurrent_tester.test_nodes_async(nodes=nodes, config=config))
    async_duration = time.time() - start_time
    
    print(f"  çº¿ç¨‹ç­–ç•¥ç”¨æ—¶: {threading_duration:.2f}s")
    print(f"  å¼‚æ­¥ç­–ç•¥ç”¨æ—¶: {async_duration:.2f}s")
    
    # éªŒè¯ä¸¤ç§ç­–ç•¥éƒ½èƒ½æ­£å¸¸å·¥ä½œ
    assert isinstance(threading_result, BatchTestResult), "çº¿ç¨‹ç­–ç•¥åº”è¯¥è¿”å›BatchTestResult"
    assert isinstance(async_result, BatchTestResult), "å¼‚æ­¥ç­–ç•¥åº”è¯¥è¿”å›BatchTestResult"
    assert len(threading_result.results) == len(nodes), "çº¿ç¨‹ç­–ç•¥ç»“æœæ•°é‡åº”è¯¥æ­£ç¡®"
    assert len(async_result.results) == len(nodes), "å¼‚æ­¥ç­–ç•¥ç»“æœæ•°é‡åº”è¯¥æ­£ç¡®"
    
    # ä¸¤ç§ç­–ç•¥çš„æ•ˆç‡éƒ½åº”è¯¥åˆç†
    max_expected_time = len(nodes) * config.timeout * 0.8  # å¹¶å‘åº”è¯¥è‡³å°‘å¿«20%
    assert threading_duration < max_expected_time, f"çº¿ç¨‹ç­–ç•¥æ•ˆç‡ä¸è¶³ï¼š{threading_duration:.2f}s > {max_expected_time:.2f}s"
    assert async_duration < max_expected_time, f"å¼‚æ­¥ç­–ç•¥æ•ˆç‡ä¸è¶³ï¼š{async_duration:.2f}s > {max_expected_time:.2f}s"
    
    print("âœ… ç­–ç•¥æ•ˆç‡å¯¹æ¯”æµ‹è¯•é€šè¿‡")

def test_system_adaptability():
    """æµ‹è¯•ç³»ç»Ÿé€‚åº”æ€§"""
    print("\nTesting system adaptability...")
    
    adaptability_manager = SystemAdaptabilityManager()
    
    # åˆ›å»ºæµ‹è¯•é€‚åº”è§„åˆ™
    rule_triggered = False
    rule_exception_occurred = False
    
    def test_adaptation_action(state: SystemState):
        nonlocal rule_triggered
        rule_triggered = True
        print("    é€‚åº”è§„åˆ™è¢«è§¦å‘")
    
    def failing_adaptation_action(state: SystemState):
        nonlocal rule_exception_occurred
        rule_exception_occurred = True
        raise Exception("Test adaptation failure")
    
    # æ·»åŠ æ­£å¸¸çš„é€‚åº”è§„åˆ™
    normal_rule = AdaptationRule(
        event_type=SystemEvent.NETWORK_INTERFACE_CHANGED,
        condition=lambda state: True,  # æ€»æ˜¯æ»¡è¶³æ¡ä»¶
        action=test_adaptation_action,
        cooldown_seconds=1,
        priority=1
    )
    
    # æ·»åŠ ä¼šå¤±è´¥çš„é€‚åº”è§„åˆ™
    failing_rule = AdaptationRule(
        event_type=SystemEvent.NETWORK_CONNECTIVITY_LOST,
        condition=lambda state: True,
        action=failing_adaptation_action,
        cooldown_seconds=1,
        priority=2
    )
    
    adaptability_manager.add_adaptation_rule(normal_rule)
    adaptability_manager.add_adaptation_rule(failing_rule)
    
    # æ¨¡æ‹Ÿç½‘ç»œæ¥å£å˜åŒ–
    print("  æ¨¡æ‹Ÿç½‘ç»œæ¥å£å˜åŒ–...")
    with patch.object(adaptability_manager, '_interfaces_changed', return_value=True):
        adaptability_manager._detect_changes()
        adaptability_manager._apply_adaptation_rules()
    
    assert rule_triggered, "é€‚åº”è§„åˆ™åº”è¯¥è¢«è§¦å‘"
    
    # æ¨¡æ‹Ÿç½‘ç»œè¿æ¥ä¸¢å¤±ï¼ˆä¼šè§¦å‘å¤±è´¥çš„è§„åˆ™ï¼‰
    print("  æ¨¡æ‹Ÿç½‘ç»œè¿æ¥ä¸¢å¤±...")
    adaptability_manager.current_state.internet_connectivity = False
    adaptability_manager.previous_state.internet_connectivity = True
    
    # ç³»ç»Ÿåº”è¯¥èƒ½å¤Ÿå¤„ç†è§„åˆ™æ‰§è¡Œå¤±è´¥è€Œä¸å´©æºƒ
    try:
        adaptability_manager._detect_changes()
        adaptability_manager._apply_adaptation_rules()
    except Exception as e:
        assert False, f"ç³»ç»Ÿé€‚åº”æ€§ç®¡ç†å™¨ä¸åº”è¯¥å› ä¸ºè§„åˆ™å¤±è´¥è€Œå´©æºƒ: {e}"
    
    # éªŒè¯ç»Ÿè®¡ä¿¡æ¯
    stats = adaptability_manager.get_statistics()
    assert isinstance(stats, dict), "ç»Ÿè®¡ä¿¡æ¯åº”è¯¥æ˜¯å­—å…¸"
    assert 'events_triggered' in stats, "ç»Ÿè®¡ä¿¡æ¯åº”è¯¥åŒ…å«äº‹ä»¶è§¦å‘æ•°"
    assert 'rules_executed' in stats, "ç»Ÿè®¡ä¿¡æ¯åº”è¯¥åŒ…å«è§„åˆ™æ‰§è¡Œæ•°"
    assert 'adaptations_successful' in stats, "ç»Ÿè®¡ä¿¡æ¯åº”è¯¥åŒ…å«æˆåŠŸé€‚åº”æ•°"
    assert 'adaptations_failed' in stats, "ç»Ÿè®¡ä¿¡æ¯åº”è¯¥åŒ…å«å¤±è´¥é€‚åº”æ•°"
    
    print(f"  ç»Ÿè®¡ä¿¡æ¯: {stats}")
    
    # åº”è¯¥æœ‰æˆåŠŸå’Œå¤±è´¥çš„é€‚åº”
    assert stats['rules_executed'] > 0, "åº”è¯¥æœ‰è§„åˆ™è¢«æ‰§è¡Œ"
    assert stats['adaptations_successful'] > 0, "åº”è¯¥æœ‰æˆåŠŸçš„é€‚åº”"
    
    print("âœ… ç³»ç»Ÿé€‚åº”æ€§æµ‹è¯•é€šè¿‡")

def test_monitoring_stability():
    """æµ‹è¯•ç›‘æ§ç¨³å®šæ€§"""
    print("\nTesting monitoring stability...")
    
    adaptability_manager = SystemAdaptabilityManager()
    
    # å¯åŠ¨ç›‘æ§
    print("  å¯åŠ¨ç³»ç»Ÿç›‘æ§...")
    adaptability_manager.start_monitoring()
    
    # ç­‰å¾…å‡ ä¸ªç›‘æ§å‘¨æœŸ
    time.sleep(2)
    
    # éªŒè¯ç›‘æ§æ­£åœ¨è¿è¡Œ
    assert adaptability_manager._monitoring_thread.is_alive(), "ç›‘æ§çº¿ç¨‹åº”è¯¥åœ¨è¿è¡Œ"
    
    # è·å–ç³»ç»ŸçŠ¶æ€
    state = adaptability_manager.get_current_state()
    assert isinstance(state, SystemState), "åº”è¯¥è¿”å›SystemStateå¯¹è±¡"
    assert state.last_updated is not None, "åº”è¯¥æœ‰æœ€åæ›´æ–°æ—¶é—´"
    
    print(f"  ç³»ç»ŸçŠ¶æ€å¥åº·: {state.is_healthy()}")
    print(f"  ç½‘ç»œæ¥å£æ•°é‡: {len(state.network_interfaces)}")
    print(f"  äº’è”ç½‘è¿é€šæ€§: {state.internet_connectivity}")
    
    # éªŒè¯çŠ¶æ€æ›´æ–°
    initial_update_time = state.last_updated
    time.sleep(1)
    
    updated_state = adaptability_manager.get_current_state()
    assert updated_state.last_updated > initial_update_time, "çŠ¶æ€åº”è¯¥è¢«æ›´æ–°"
    
    # åœæ­¢ç›‘æ§
    print("  åœæ­¢ç³»ç»Ÿç›‘æ§...")
    adaptability_manager.stop_monitoring()
    
    # éªŒè¯ç›‘æ§å·²åœæ­¢
    time.sleep(1)
    assert not adaptability_manager._monitoring_thread.is_alive(), "ç›‘æ§çº¿ç¨‹åº”è¯¥å·²åœæ­¢"
    
    print("âœ… ç›‘æ§ç¨³å®šæ€§æµ‹è¯•é€šè¿‡")

def test_concurrent_test_cancellation():
    """æµ‹è¯•å¹¶å‘æµ‹è¯•å–æ¶ˆåŠŸèƒ½"""
    print("\nTesting concurrent test cancellation...")
    
    concurrent_tester = ConcurrentLatencyTester()
    
    # åˆ›å»ºèŠ‚ç‚¹
    nodes = []
    for i in range(15):
        node = Node(
            uuid=f"cancel-test-{i}",
            remark=f"cancel_node_{i}",
            protocol="vless",
            address="127.0.0.1",
            port=9000 + i
        )
        nodes.append(node)
    
    config = ConcurrentTestConfig(
        max_concurrent=3,
        timeout=2.0,  # è¾ƒé•¿çš„è¶…æ—¶æ—¶é—´
        strategy=TestStrategy.THREADING
    )
    
    # åœ¨å¦ä¸€ä¸ªçº¿ç¨‹ä¸­å¯åŠ¨æµ‹è¯•
    result_container = []
    exception_container = []
    
    def run_test():
        try:
            result = concurrent_tester.test_nodes_threaded(
                nodes=nodes,
                config=config
            )
            result_container.append(result)
        except Exception as e:
            exception_container.append(e)
    
    print("  å¯åŠ¨å¹¶å‘æµ‹è¯•...")
    test_thread = threading.Thread(target=run_test)
    test_thread.start()
    
    # ç­‰å¾…æµ‹è¯•å¼€å§‹
    time.sleep(0.5)
    
    # éªŒè¯æµ‹è¯•æ­£åœ¨è¿è¡Œ
    assert concurrent_tester.is_testing(), "æµ‹è¯•åº”è¯¥æ­£åœ¨è¿è¡Œ"
    
    # å–æ¶ˆæµ‹è¯•
    print("  å–æ¶ˆæµ‹è¯•...")
    concurrent_tester.cancel_test()
    
    # ç­‰å¾…æµ‹è¯•çº¿ç¨‹å®Œæˆ
    test_thread.join(timeout=10)
    
    # éªŒè¯æµ‹è¯•å·²å®Œæˆä¸”æ²¡æœ‰å¼‚å¸¸
    assert not test_thread.is_alive(), "æµ‹è¯•çº¿ç¨‹åº”è¯¥å·²å®Œæˆ"
    assert len(exception_container) == 0, f"æµ‹è¯•å–æ¶ˆä¸åº”è¯¥äº§ç”Ÿå¼‚å¸¸: {exception_container}"
    
    # éªŒè¯æµ‹è¯•ä¸å†è¿è¡Œ
    assert not concurrent_tester.is_testing(), "æµ‹è¯•åº”è¯¥å·²åœæ­¢"
    
    print("âœ… å¹¶å‘æµ‹è¯•å–æ¶ˆåŠŸèƒ½æµ‹è¯•é€šè¿‡")

def test_performance_statistics():
    """æµ‹è¯•æ€§èƒ½ç»Ÿè®¡å‡†ç¡®æ€§"""
    print("\nTesting performance statistics accuracy...")
    
    concurrent_tester = ConcurrentLatencyTester()
    
    # æ¸…é™¤ä¹‹å‰çš„ç»Ÿè®¡
    concurrent_tester._total_tests_run = 0
    concurrent_tester._total_successful_tests = 0
    concurrent_tester._total_failed_tests = 0
    
    # åˆ›å»ºæµ‹è¯•èŠ‚ç‚¹
    nodes = []
    for i in range(6):
        node = Node(
            uuid=f"stats-test-{i}",
            remark=f"stats_node_{i}",
            protocol="vless",
            address="127.0.0.1",
            port=7000 + i
        )
        nodes.append(node)
    
    config = ConcurrentTestConfig(
        max_concurrent=3,
        timeout=0.5,
        strategy=TestStrategy.THREADING
    )
    
    # æ‰§è¡Œæµ‹è¯•
    result = concurrent_tester.test_nodes_threaded(
        nodes=nodes,
        config=config
    )
    
    # éªŒè¯æ‰¹é‡ç»“æœç»Ÿè®¡
    assert result.total_nodes == len(nodes), f"æ€»èŠ‚ç‚¹æ•°åº”è¯¥æ˜¯{len(nodes)}"
    assert len(result.results) == len(nodes), f"ç»“æœæ•°é‡åº”è¯¥æ˜¯{len(nodes)}"
    assert result.completed_nodes >= 0, "å®ŒæˆèŠ‚ç‚¹æ•°åº”è¯¥éè´Ÿ"
    assert result.completed_nodes <= len(nodes), "å®ŒæˆèŠ‚ç‚¹æ•°ä¸åº”è¯¥è¶…è¿‡æ€»æ•°"
    
    print(f"  æ€»èŠ‚ç‚¹æ•°: {result.total_nodes}")
    print(f"  å®ŒæˆèŠ‚ç‚¹æ•°: {result.completed_nodes}")
    print(f"  å¤±è´¥èŠ‚ç‚¹æ•°: {result.failed_nodes}")
    print(f"  æµ‹è¯•æŒç»­æ—¶é—´: {result.test_duration:.2f}s")
    
    # éªŒè¯å…¨å±€ç»Ÿè®¡
    stats = concurrent_tester.get_statistics()
    assert stats['total_tests_run'] == len(nodes), f"å…¨å±€æµ‹è¯•æ€»æ•°åº”è¯¥æ˜¯{len(nodes)}"
    assert stats['total_successful_tests'] >= 0, "æˆåŠŸæµ‹è¯•æ•°åº”è¯¥éè´Ÿ"
    assert stats['total_failed_tests'] >= 0, "å¤±è´¥æµ‹è¯•æ•°åº”è¯¥éè´Ÿ"
    assert (stats['total_successful_tests'] + stats['total_failed_tests'] == 
            stats['total_tests_run']), "æˆåŠŸæ•°+å¤±è´¥æ•°åº”è¯¥ç­‰äºæ€»æ•°"
    
    print(f"  å…¨å±€ç»Ÿè®¡: {stats}")
    
    # éªŒè¯æˆåŠŸç‡è®¡ç®—
    expected_success_rate = (
        stats['total_successful_tests'] / stats['total_tests_run'] * 100
        if stats['total_tests_run'] > 0 else 0
    )
    assert abs(stats['success_rate'] - expected_success_rate) < 0.01, "æˆåŠŸç‡è®¡ç®—åº”è¯¥å‡†ç¡®"
    
    print("âœ… æ€§èƒ½ç»Ÿè®¡å‡†ç¡®æ€§æµ‹è¯•é€šè¿‡")

if __name__ == "__main__":
    print("ğŸ§ª å¼€å§‹æ€§èƒ½ä¼˜åŒ–å±æ€§æµ‹è¯•...")
    
    test_concurrent_processing_efficiency()
    test_async_vs_threading_strategies()
    test_system_adaptability()
    test_monitoring_stability()
    test_concurrent_test_cancellation()
    test_performance_statistics()
    
    print("\nğŸ‰ æ‰€æœ‰æ€§èƒ½ä¼˜åŒ–å±æ€§æµ‹è¯•éƒ½é€šè¿‡äº†ï¼")